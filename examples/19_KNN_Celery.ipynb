{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the user defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "sys.path.insert(0, os.path.abspath('..')+'/classifiers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "param_dict = {\"n_neighbors\": range(1, 50),\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# userObjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CeleryTasks import run_clf_celery\n",
    "\n",
    "clf_name = 'KNeighborsClassifier'\n",
    "dataset_name = 'load_breast_cancer'\n",
    "\n",
    "\n",
    "\n",
    "def objectiveKNNCelery(args_list):\n",
    "    global clf_name,dataset_name\n",
    "    process_queue =[]\n",
    "    \n",
    "    for hyper_par in args_list:\n",
    "        process = run_clf_celery.delay(clf_name, dataset_name, hyper_par)\n",
    "        process_queue.append(process)\n",
    "    \n",
    "    results = []\n",
    "    for process in process_queue:\n",
    "        result = process.get(timeout=100)\n",
    "        results.append(result)\n",
    "           \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_Dict = dict()\n",
    "conf_Dict['batch_size'] = 5\n",
    "conf_Dict['num_iteration'] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_user = Tuner(param_dict, objectiveKNNCelery, conf_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'param_dict': {'n_neighbors': range(1, 50),\n",
       "  'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']},\n",
       " 'userObjective': <function __main__.objectiveKNNCelery(args_list)>,\n",
       " 'domain_size': 5000,\n",
       " 'initial_random': 1,\n",
       " 'num_iteration': 5,\n",
       " 'objective': 'maximize',\n",
       " 'batch_size': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuner_user.getConf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = tuner_user.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best hyper parameters:',results['best_hyper_parameter'])\n",
    "print('best objective:',results['best_objective'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sample hyper parameters tried:',len(results['hyper_parameters_tried']))\n",
    "print(results['hyper_parameters_tried'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Sample objective values',len(results['objective_values']))\n",
    "print(results['objective_values'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the variation of actual objective values of the tried results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Size = 201 \n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(30,5))\n",
    "plt.title('Variation of Objective',fontsize=20)\n",
    "plt.plot(results['objective_values'][:Size],lw=4,label='BL')\n",
    "plt.xlabel('Configurations', fontsize=25)\n",
    "plt.ylabel('objective_values',fontsize=25)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the variation of Max objective values of the tried results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Size = 201 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "results_obj = np.array(results['objective_values'])\n",
    "\n",
    "y_max=[]\n",
    "for i in range(results_obj.shape[0]):\n",
    "    y_max.append(np.max(results_obj[:i+1]))\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure(figsize=(30,5))\n",
    "plt.title('Max variation of Objective',fontsize=20)\n",
    "plt.plot(y_max[:Size],lw=4,label='BL')\n",
    "plt.xlabel('Configurations', fontsize=25)\n",
    "plt.ylabel('objective_values',fontsize=25)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(prop={'size': 30})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pp.pprint(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
